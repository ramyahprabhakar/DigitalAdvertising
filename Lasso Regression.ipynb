{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "## Ramya Prabhakar\n",
    "### Often in marketing analytics we have too much data to do a simple multiple regression. That is, there are too many possible\n",
    "### predictors to consider at once. Multiple regression falls apart in these instances because of multicollinearity and because\n",
    "### often many variables will be significant, leaving us with no real idea what the few true factors driving the result we want\n",
    "### truly are.\n",
    "### Lasso stands for least absolute shrinkage and selection operator.\n",
    "### LASSO is great in that it preforms feature (predictor) variable selection. That is, it automatically selects the most \n",
    "### powerful variables, the variables that explain the most variance in our regression, while leaving out those that explain\n",
    "### little unique variance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd\n",
    "import pandas\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data can be found in github repository\n",
    "# read the data using pandas\n",
    "alldata = pd.read_csv('finalmaster-ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all predictors\n",
    "allvariablenames = list(alldata.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first 8 predictors since they're invalid\n",
    "newdata = alldata.drop(columns = ['# Purchases', 'B01001001', 'B01001002', 'B01001003', 'B01001004', 'B01001005', 'B01001006', 'B01001007' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of all predictors after removing the invalid columns\n",
    "listofallpredictors = list(newdata.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load predictors into a dataframe\n",
    "predictors = newdata[listofallpredictors]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load target into a dataframe\n",
    "target = alldata['# Purchases']                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test sets, with 30% retained for the test set\n",
    "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, target, test_size=.3, random_state=123)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.496e+00, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.098e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.329e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.051e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.739e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.736e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 9.483e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.579e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.483e-01, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.383e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=5.917e-01, previous alpha=5.383e-01, with an active set of 16 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.100e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.867e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.050e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.013e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=1.986e-01, previous alpha=1.960e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.426e-01, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=7.131e-02, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=7.126e-02, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=6.413e-02, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 106 iterations, alpha=5.744e-02, previous alpha=5.107e-02, with an active set of 83 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.439e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.037e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=7.202e-01, previous alpha=7.200e-01, with an active set of 12 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.916e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.645e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.456e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.867e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.734e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.709e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.692e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=1.668e-01, previous alpha=1.607e-01, with an active set of 45 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.572e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.132e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.640e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.560e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.932e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.737e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=1.702e-01, previous alpha=1.687e-01, with an active set of 45 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.644e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.178e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.316e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.155e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.203e-01, previous alpha=3.135e-01, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.896e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=9.481e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.251e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.529e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=7.347e-01, previous alpha=5.991e-01, with an active set of 11 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.147e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.014e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.010e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.693e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.099e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.948e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.137e-01, previous alpha=3.116e-01, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.644e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.822e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 37 iterations, alpha=2.062e-01, previous alpha=1.984e-01, with an active set of 34 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.372e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\pingr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.825e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Use lassolarscv and make a model and fit the training data onto the new model\n",
    "model=LassoLarsCV(cv=10).fit(pred_train,tar_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a predictors model data frame that contains the list of all possible predictor variables\n",
      "Label the columns of the predictors model data frame\n",
      "Assign the co efficients of the model to the coeff column in the predictors model data frame\n"
     ]
    }
   ],
   "source": [
    "#build coefficent chart\n",
    "print('Create a predictors model data frame that contains the list of all possible predictor variables' )\n",
    "predictors_model=pd.DataFrame(listofallpredictors)\n",
    "print('Label the columns of the predictors model data frame' )\n",
    "predictors_model.columns = ['label']\n",
    "print('Assign the co efficients of the model to the coeff column in the predictors model data frame' )\n",
    "predictors_model['coeff'] = model.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterate through each row of the predictors model data frame and print the positive co efficients\n",
      "['B01001036' 2.784856986420159]\n",
      "['B01001037' 0.9234930857404328]\n",
      "['B01001038' 0.9491459380764333]\n",
      "['B02001005' 0.3919782979991068]\n",
      "['B13014026' 0.22147975335090184]\n",
      "['B13014027' 0.05121418112617723]\n",
      "['B19001017' 1.6058830181449382]\n"
     ]
    }
   ],
   "source": [
    "print('Iterate through each row of the predictors model data frame and print the positive co efficients')\n",
    "for index, row in predictors_model.iterrows():\n",
    "    if row['coeff'] > 0:\n",
    "        print(row.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data MSE\n",
      "22525.63625144556\n"
     ]
    }
   ],
   "source": [
    "#Calculate the mean squared error for the training set:        \n",
    "train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
    "print ('Training Data MSE')\n",
    "print(train_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data MSE\n",
      "41573.80112905681\n"
     ]
    }
   ],
   "source": [
    "#Calculate the mean squared error for the test set:        \n",
    "test_error=mean_squared_error(tar_test, model.predict(pred_test))\n",
    "print ('Testing Data MSE')\n",
    "print(test_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data R-square\n",
      "0.2227648778602469\n"
     ]
    }
   ],
   "source": [
    "#Calculate the r square for the training set\n",
    "rsquared_train=model.score(pred_train,tar_train)\n",
    "print ('Training data R-square')\n",
    "print(rsquared_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data R-square\n",
      "0.1753817900469531\n"
     ]
    }
   ],
   "source": [
    "#Calculate the r square for the test set\n",
    "rsquared_test=model.score(pred_test,tar_test)\n",
    "print ('Testing data R-square')\n",
    "print(rsquared_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y interecept:\n",
      "2.8174754145509553\n"
     ]
    }
   ],
   "source": [
    "#print the y intercept of the model\n",
    "print(\"y interecept:\")\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Women in the age groups of 30 to 44, People of Asian only origin, households with income over $200,000 or more and women 15-50 years who had a birth in the past 12 months by marital status and educational attainment make the most of the purchases that are made in our example.\n",
      "\n",
      "\n",
      " Top two census variables that most steeply predict sales are: B01001036 – Females aged 30-34 tend to make more purchases B19001017 - Households with income over $200,000.\n",
      "\n",
      "\n",
      " Training Data MSE - 22525.64 Testing Data MSE - 41573.8 The training and test sets have different mean square errors. Practically the mean square error is a measure of the dispersion within a data set. The Mean Squared Error (MSE) is a measure of how close a fitted line is to data points in a given data set. In our example, the training set has a lesser mean square error than the test set. This seems logically correct, since the training set contains 70% of the data while the test set contains only 30% of the data. Increasing the sample size leads to a reduction in the dispersion.\n",
      " \n",
      "\n",
      " Training data R-square 0.2227648778602469 testing data R-square 0.1753817900469531 Considering the r square value of the testing data set, it can be concluded that the given census data predicts the overall sales correctly, 17.5% of the times. This does not give us much confidence in the model since we would like to be able to predict the correct possible sales values more than 17.5% of the times. \n",
      "\n",
      "\n",
      " The baseline sales number is 2.82. This means that if all the predictor variables (x) are set to zero, we will still have a baseline sale of 2.82 units.\n"
     ]
    }
   ],
   "source": [
    "print(\" Women in the age groups of 30 to 44, People of Asian only origin, households with income over $200,000 or more and women 15-50 years who had a birth in the past 12 months by marital status and educational attainment make the most of the purchases that are made in our example.\\n\")\n",
    "print(\"\\n Top two census variables that most steeply predict sales are: B01001036 – Females aged 30-34 tend to make more purchases B19001017 - Households with income over $200,000.\\n\")\n",
    "print(\"\\n Training Data MSE - 22525.64 Testing Data MSE - 41573.8 The training and test sets have different mean square errors. Practically the mean square error is a measure of the dispersion within a data set. The Mean Squared Error (MSE) is a measure of how close a fitted line is to data points in a given data set. In our example, the training set has a lesser mean square error than the test set. This seems logically correct, since the training set contains 70% of the data while the test set contains only 30% of the data. Increasing the sample size leads to a reduction in the dispersion.\\n \")\n",
    "print( \"\\n Training data R-square 0.2227648778602469 testing data R-square 0.1753817900469531 Considering the r square value of the testing data set, it can be concluded that the given census data predicts the overall sales correctly, 17.5% of the times. This does not give us much confidence in the model since we would like to be able to predict the correct possible sales values more than 17.5% of the times. \\n\")       \n",
    "print (\"\\n The baseline sales number is 2.82. This means that if all the predictor variables (x) are set to zero, we will still have a baseline sale of 2.82 units.\")      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
