{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Ad Analyses\n",
    "## Ramya Prabhakar\n",
    "### This is advertising campaign engagement data from Facebook. Each row is an ad that ran on the platform. \n",
    "### It includes the amount spent on the campaign, and other outcome/engagement data. Here, I do some analyses that tease out \n",
    "### some insights on how to advertise more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required packages\n",
    "\n",
    "import pandas as pd\n",
    "import arrow\n",
    "from sklearn import linear_model\n",
    "# import stats models for the reg statistics\n",
    "import statsmodels.api as sm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data uploaded in github\n",
    "# Read the travel pony facebook csv file using pandas\n",
    "df = pd.read_csv('Travel Pony Facebook.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column CPI and calculate the same using amount spent/impressions\n",
    "df['CPI'] = df['Amount Spent (USD)']/df['Impressions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list to note down the day of the week\n",
    "dayOfWeek = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the day of the weeek as a numerical value from the start date field and store it in the list dayOfWeek\n",
    "for i,row in df.iterrows():\n",
    "    dt = arrow.get(row['Start Date'], 'M/D/YY')\n",
    "    x = dt.isoweekday()\n",
    "    dayOfWeek.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column in the dataframe and store the day of the week corresponding to the date\n",
    "df['dayOfWeek']=pd.Series(dayOfWeek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pivot table to sum the number of times each day of the week is repeated\n",
    "pivot_dayOfWeek = df.pivot_table(index='dayOfWeek', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best day of the week: 6 ;CPI 1.3117197697515264\n",
      "Worst day of the week: 5 ;CPI 2.05663914118258\n"
     ]
    }
   ],
   "source": [
    "#Calculate the best and worst days of the week based on the max and the min CPI    \n",
    "dw=pd.DataFrame(pivot_dayOfWeek,columns=['CPI','dayOfWeek']) \n",
    "print(\"Best day of the week:\",dw['CPI'].idxmin(),\";CPI\",dw['CPI'][dw['CPI'].idxmin()])\n",
    "print(\"Worst day of the week:\",dw['CPI'].idxmax(),\";CPI\",dw['CPI'][dw['CPI'].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the correlation between Amount Spent and the following variables:\n",
    "#- Reach\n",
    "#- Frequency \n",
    "#- Unique Clicks\n",
    "#- Page Likes\n",
    "\n",
    "data_corr=df.corr()\n",
    "reach_amtSpent=data_corr['Reach']['Amount Spent (USD)']\n",
    "freq_amtSpent=data_corr['Frequency']['Amount Spent (USD)']\n",
    "unqClicks_amtSpent=data_corr['Unique Clicks']['Amount Spent (USD)']\n",
    "pgLikes_amtSpent=data_corr['Page Likes']['Amount Spent (USD)']\n",
    "\n",
    "data={'variable':['Reach','Frequency','Unique Clicks','Page Likes'],'correlation':[reach_amtSpent,freq_amtSpent,unqClicks_amtSpent,pgLikes_amtSpent]}\n",
    "corr_df=pd.DataFrame(data,columns=['variable','correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount Spent (USD) has the strongest Correlation with  Unique Clicks = 0.8829931774784341\n"
     ]
    }
   ],
   "source": [
    "# Which correlation is the strongest? What does that mean practically? \n",
    "# (respond in a tweet or less)\n",
    "print(\"Amount Spent (USD) has the strongest Correlation with \",corr_df['variable'][corr_df['correlation'].idxmax()],\"=\",corr_df['correlation'][corr_df['correlation'].idxmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, perform a simple multiple regression analysis where \n",
    "# Unique Clicks is the dependent variable and Reach and Frequency are the independent\n",
    "# (predictor) variables.\n",
    "# What variable most strongly predicts unique clicks? \n",
    "# What does that mean practically? (respond in a tweet or less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear_model from sklearn\n",
      "Intercept: \n",
      " 29.227730390224764\n",
      "Coefficients: \n",
      " [ 2.06474936e-03 -2.50632823e+01]\n",
      "[545.46559791 433.95502979 519.77018255 ...   4.39363526   4.45970724\n",
      "  11.70488637]\n",
      " R squared value is  0.534339731180361\n"
     ]
    }
   ],
   "source": [
    "#use the linear_model from sklearn\n",
    "df = pd.read_csv('Travel Pony Facebook.csv')\n",
    "\n",
    "x1=df[['Reach','Frequency']]\n",
    "y1=df['Unique Clicks']\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x1, y1)\n",
    "\n",
    "print (\"Using Linear_model from sklearn\")\n",
    "print('Intercept: \\n', regr.intercept_)\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "    \n",
    "#predicted Y for the regression model\n",
    "predictions = regr.predict(x1)\n",
    "print(predictions)\n",
    "\n",
    "# r2 value\n",
    "print(\" R squared value is \", regr.score(x1,y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      const   Reach  Frequency\n",
      "0       1.0  278117   2.314303\n",
      "1       1.0  221255   2.079090\n",
      "2       1.0  267915   2.499069\n",
      "3       1.0  280332   2.365406\n",
      "4       1.0   14269   1.000420\n",
      "5       1.0    7096   1.018743\n",
      "6       1.0   29437   1.000000\n",
      "7       1.0   30320   1.018239\n",
      "8       1.0   25951   1.026820\n",
      "9       1.0   49038   1.000000\n",
      "10      1.0   32851   1.023287\n",
      "11      1.0   53974   1.000000\n",
      "12      1.0   81149   1.004128\n",
      "13      1.0   81237   1.000000\n",
      "14      1.0   68209   1.000000\n",
      "15      1.0   45828   1.000000\n",
      "16      1.0    8466   1.018663\n",
      "17      1.0    1111   1.001800\n",
      "18      1.0    5043   1.008527\n",
      "19      1.0   10825   1.017644\n",
      "20      1.0    3384   1.002660\n",
      "21      1.0    8054   1.001738\n",
      "22      1.0   19465   1.000000\n",
      "23      1.0    6698   1.016124\n",
      "24      1.0   15852   1.020250\n",
      "25      1.0   21453   1.019391\n",
      "26      1.0    8449   1.010179\n",
      "27      1.0   19738   1.000000\n",
      "28      1.0   16716   1.000000\n",
      "29      1.0   13166   1.000000\n",
      "...     ...     ...        ...\n",
      "3675    1.0     657   1.000000\n",
      "3676    1.0      32   1.000000\n",
      "3677    1.0      77   1.000000\n",
      "3678    1.0    1531   1.003266\n",
      "3679    1.0     493   1.004057\n",
      "3680    1.0     251   1.019920\n",
      "3681    1.0      38   1.026316\n",
      "3682    1.0     139   1.007194\n",
      "3683    1.0    1738   1.006329\n",
      "3684    1.0     112   1.008929\n",
      "3685    1.0    4301   3.529644\n",
      "3686    1.0    9214   4.164532\n",
      "3687    1.0    7648   4.597411\n",
      "3688    1.0    8149   4.267149\n",
      "3689    1.0    6330   2.853397\n",
      "3690    1.0    6088   2.811104\n",
      "3691    1.0    8963   1.482874\n",
      "3692    1.0     229   1.026201\n",
      "3693    1.0     626   1.062300\n",
      "3694    1.0     615   1.016260\n",
      "3695    1.0     702   1.004274\n",
      "3696    1.0    1143   1.699913\n",
      "3697    1.0      54   1.037037\n",
      "3698    1.0     513   1.000000\n",
      "3699    1.0     342   1.000000\n",
      "3700    1.0     298   1.003356\n",
      "3701    1.0     514   1.060311\n",
      "3702    1.0     111   1.000000\n",
      "3703    1.0     143   1.000000\n",
      "3704    1.0    4711   1.087243\n",
      "\n",
      "[3705 rows x 3 columns]\n",
      "<statsmodels.regression.linear_model.OLS object at 0x0000026C7C1523C8>\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Unique Clicks   R-squared:                       0.534\n",
      "Model:                            OLS   Adj. R-squared:                  0.534\n",
      "Method:                 Least Squares   F-statistic:                     2124.\n",
      "Date:                Thu, 18 Oct 2018   Prob (F-statistic):               0.00\n",
      "Time:                        14:41:54   Log-Likelihood:                -15907.\n",
      "No. Observations:                3705   AIC:                         3.182e+04\n",
      "Df Residuals:                    3702   BIC:                         3.184e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         29.2277      2.525     11.575      0.000      24.277      34.178\n",
      "Reach          0.0021   3.22e-05     64.054      0.000       0.002       0.002\n",
      "Frequency    -25.0633      2.495    -10.047      0.000     -29.954     -20.172\n",
      "==============================================================================\n",
      "Omnibus:                     5087.566   Durbin-Watson:                   0.805\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4867968.237\n",
      "Skew:                           7.291   Prob(JB):                         0.00\n",
      "Kurtosis:                     179.977   Cond. No.                     1.19e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.19e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "The variable Frequency strongly predicts the number of Unique clicks since it has a greater co efficient!\n"
     ]
    }
   ],
   "source": [
    "#now use the statsmodels to confirm the findings\n",
    "      \n",
    "X2 = sm.add_constant(x1)\n",
    "print (X2)\n",
    "est = sm.OLS(y1, X2)\n",
    "print (est)\n",
    "est2 = est.fit()\n",
    "print(est2.summary()) \n",
    "\n",
    "X = df[['Reach', 'Frequency']]\n",
    "y = df['Unique Clicks']\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "model.summary()\n",
    "\n",
    "print (\"\\nThe variable Frequency strongly predicts the number of Unique clicks since it has a greater co efficient!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
